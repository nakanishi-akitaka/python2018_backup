
# -*- coding: utf-8 -*-
"""
Created on Sat Jul 21 17:32:43 2018

@author: Akitaka
"""

機械学習の基本的な流れ
ref:
実践的なデータ解析の手順
http://univprof.com/archives/16-02-11-2849465.html
データ解析の手順の各段階における手法
http://univprof.com/archives/16-05-01-2850729.html
いまさら聞けない？scikit-learnのキホン
https://dev.classmethod.jp/machine-learning/introduction-scikit-learn/


どの機械学習を使えばいいか？が分かるフローチャート
Choosing the right estimator
http://scikit-learn.org/stable/tutorial/machine_learning_map/




sklearnのクラスと関数一覧
API Reference
http://scikit-learn.org/stable/modules/classes.html



kNNのハイパーパラメータ
https://datachemeng.com/knn/
ハイパーパラメータ kの決め方
回帰や分類:CVで決める 正解率、R^2
適用範囲:試行錯誤(一般的にはk=5,10)
ADを決める時の閾値：3σ法より99.7%




One-Class Support Vector Machineのハイパーパラメータ 
https://datachemeng.com/ocsvm/
ν = 0.03 3σ法より99.7%
γはグラム行列の分散を最大化するものを選ぶ
http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
デフォルトはν=0.5



ランダムフォレストのハイパーパラメータ
https://datachemeng.com/randomforest/
説明変数の選択の割合：CVで決定
サブデータセットの数：基本的には1000
決定木の深さ：深いほどいい

scikit learnのデフォルト値
http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html
説明変数の選択の割合：max_features=sqrt(n_features))
サブデータセットの数：n_estimators=10
決定木の深さ：max_depth=None (総ての葉がpureになるまで)

https://twitter.com/fmkz___/status/1020503846882140160
SVRはこれでいいんだけど、RFのパラメータチューニングのいいやり方知っている方いませんか？
金子さんに前聞いたらdepthはふらずにでtreeの数と説明変数の数だけふると良いとおっしゃってしたね。
あ、depthは一番深いところまでいっちゃってください！





SVM・SVRのハイパーパラメータの値の候補はどうして2のべき乗・累乗なのか？
http://univprof.com/archives/16-06-25-4229971.html
SVMのC・γの候補は、
C: 2^-10,  2^-9,  …,  2^14,  2^15 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

SVRのC・ε・γの候補は
C: 2^-10,  2^-9,  …,  2^14,  2^15 
ε: 2^-15,  2^-14,  …,  2^9,  2^10 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

https://datachemeng.com/supportvectormachine/
SVMのC・γの候補は、
C: 2^-5,  2^-4,  …,  2^9,  2^10
γ: 2^-10, 2^-9,  …,  2^4,  2^5

https://datachemeng.com/supportvectorregression/
SVRのC・ε・γの候補は
C: 2^-5,  2^-4,  …,  2^9,  2^10 
ε: 2^-10, 2^-9,  …,  2^-1, 2^0 
γ: 2^-20, 2^-19, …,  2^9,  2^10




あなたはサポートベクターマシン・回帰 (Support Vector Machine or Regression, SVM or SVR) 
におけるハイパーパラメータの設定に時間がかかっていませんか？
http://univprof.com/archives/16-07-14-4701508.html
SVRのC・ε・γの候補は
C: 2^-10,  2^-9,  …,   2^9,  2^10
ε: 2^-15,  2^-14,  …,  2^9,  2^10 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

[Pythonコードあり] サポートベクター回帰(Support Vector Regression, SVR)の
ハイパーパラメータを高速に最適化する方法
https://datachemeng.com/fastoptsvrhyperparams/
C の候補: 2^-5, 2^-4, …, 2^9, 2^10 (16通り)
ε (イプシロン) の候補: 2^-10, 2^-9, …, 2^-1, 2^0 (11通り)
γ (ガンマ) の候補: 2^-20, 2^-19, …, 2^9, 2^10 (31通り)

高速最適化の手順は2通り
金子研究室：
    1.グラム行列の分散を最大にするγを計算
    2.γopt＋C=3で、εのみ最適化
    3.γopt+εoptで、Cを最適化
    4.εopt+Coptで、γを最適化
大学教授のブログ：
    1.グラム行列の分散を最大にするγを計算
    2.γoptで、Cとεを同時に最適化
ref:
https://datachemeng.com/fastoptsvrhyperparams
http://univprof.com/archives/16-07-14-4701508.html



クロスバリデーション/CVでの分割数
n_splits = 2, 5
https://datachemeng.com/doublecrossvalidation/
http://univprof.com/archives/16-06-12-3889388.html
n_splits = 2, 5, 10
https://datachemeng.com/modelvalidation/


分割方法について
20180426
https://mail.google.com/mail/u/0/#sent/RdDgqcJHpWcvcDjPgjkjXHLgLnDfdlQzrnZXHZlrxmfB
[1c] 分割方法について調べる
KFoldだと、単純に順番通りに分割する
　データの偏りがあった時、各fold間で性能が大きく異なる
StratifiedKFold（デフォルト）では、データないの偏りをなるべく維持しようとする
　少数データの数が少ないと分割ができない場合もある
ShuffleSplitは単純にランダムサンプリングを行う
LeaveOneOutは1つだけを取り出す
　データ数が少ないときに有効

http://scikit-learn.org/0.18/modules/cross_validation.html
> As a general rule, most authors, and empirical evidence,
> suggest that 5- or 10- fold cross validation should be preferred to LOO.
LeaveOneOutは一般的にはあまり使わない？
> ShuffleSplit is thus a good alternative to KFold cross validation
> that allows a finer control on the number of iterations
> and the proportion of samples on each side of the train / test split.
ShuffleSplitが良いらしい

<ref>
scikit learn の Kfold, StratifiedKFold, ShuffleSplit の違い
http://nakano-tomofumi.hatenablog.com/entry/2018/01/15/172427
Machine Learning with Scikit Learn (Part II)
http://aidiary.hatenablog.com/entry/20150826/1440596779
3.1. Cross-validation: evaluating estimator performance
http://scikit-learn.org/0.18/modules/cross_validation.html
【翻訳】scikit-learn 0.18 User Guide 3.1. クロスバリデーション：推定器の成果を評価する
https://qiita.com/nazoking@github/items/13b167283590f512d99a
活動記録　2018/04/11
</ref>




20180718
https://mail.google.com/mail/u/0/#sent/QgrcJHsbjCZNCXqKkMlpLbTXWjKWfzHljSl
Kfold(shuffle=True)とShuffleSplit の違い
1.train, testのサイズ:
    KFoldは常に1:k-1(k=分割数), ShuffleSplitは(分割数とは無関係に)任意の変更が可能
    つまり、trainにもtestにも使わないデータもあり得る。データが多すぎる時に有効
    n_splits:繰り返しの数(デフォ10), test_size:testデータのサイズ(デフォ0.1)
2.CVの各イテレーションで使うデータセット:
    KFold：どれも必ず一度だけtestとして使う。最初にランダムに分割しても
    ShuffleSplit:毎回ランダムに抽出するので、何度もtestに使うもの、一度も使わないものがありえる
example:
test3_shuffle.py

ref:
http://nakano-tomofumi.hatenablog.com/entry/2018/01/15/172427
https://stackoverflow.com/questions/34731421/whats-the-difference-between-kfold-and-shufflesplit-cv
http://aidiary.hatenablog.com/entry/20150826/1440596779
https://qiita.com/nazoking@github/items/13b167283590f512d99a
http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html
http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html






異なるデータセットでの評価方法
http://univprof.com/archives/16-07-04-4453136.html
OK: MAE, NG: R^2








二値類　二次元でのグラフ化
ref: https://pythondatascience.plavox.info/matplotlib/散布図
http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html




あなたのデータに主成分分析して大丈夫？～離散値データや連続値データ～
http://univprof.com/archives/16-05-15-3227035.html
Q.離散値のデータに対して主成分分析を行ってよいのでしょうか？
A.行ってよいです。ただ、適切な主成分軸を計算できない可能性があるため注意が必要です。
データが正規分布になっていることが前提
離散値データは、基本的に正規分布ではない
※連続値データだからといって正規分布になるわけではない
→
データが正規分布に従うことを仮定しない方法
    独立成分分析 (Independent Component Analysis, ICA)
    Kernel Independent Component (KICA)
    自己組織化写像 (Self-Organizing Map, SOM)
    Generative Topographic Map (GTM)
    Stochastic Neighbor Embedding (SNE)
    t-distributed Stochastic Neighbor Embedding (t-SNE)




あなたは正しい場面でディープラーニングを使用していますか？～ディープラーニングの利用条件～
http://univprof.com/archives/16-05-13-3200949.html
うまくいくのは、用いるデータ数が膨大であるときだけ
→少ないなら、SVMなどシンプルなものがよい
昔からあるが、流行らなかったわけ
    多層にすることでネットワークに学習すべきパラメータの数が急に増える
    1000~2000ぐらいのデータでは過学習する
→シンプルなニューラルネットワークが使われる
→CPU性能アップ＆データ大量ゲット可能
→ディープラーニングに注目




変数 (もしくは記述子や特徴量) の前処理の仕方
http://univprof.com/archives/16-02-21-2864891.html
削除すべき変数
    1.全く同じ値をもつデータの割合がm以上の変数
    2.他の変数との相関係数の絶対値がn以上の変数





ダブルクロスバリデーション/二重交差検証/DCVは繰り返しやるもの
http://univprof.com/archives/16-06-12-3889388.html
ダブルクロスバリデーションを複数回繰り返すことで (たとえば100回繰り返すことで)、
どれくらいr2DCV・RMSEDCV・正解率DCVにばらつきがあるのかを検討することが重要

https://datachemeng.com/doublecrossvalidation/
ダブルクロスバリデーションにおける外側のクロスバリデーションの推定値と実測値との
比較を行うことで、モデルの推定精度を検証する
ダブルクロスバリデーションを何回か行って、
その結果の平均やばらつきを確認するとより細かくモデルを検証できます。




ダブルクロスバリデーション/二重交差検証/DCVの意義
https://datachemeng.com/modelvalidation/
https://datachemeng.com/doublecrossvalidation/
データ数が大　→　トレーニング + バリデーション + テスト
データ数が中　→　クロスバリデーション + テスト
データ数が小　→　ダブルクロスバリデーション
CVは2,5,10-foldが一般的

あくまでも推定性能の検証に用いるもの！
train_test_splitと併用するのはおかしい！？