# -*- coding: utf-8 -*-
"""
Created on Wed Aug  1 13:08:37 2018

@author: Akitaka
"""

[1a2] 回帰計算の結果はどう表示するべき？
example:
test0_rgr.py
mylibrary.py

DCVの予測値については、一旦パス
関数をprint_gscv_score_rgrに改名


[1b] サイトで勉強２　大学教授のブログ (データ分析相談所)
http://univprof.com/

1.07/06~07/26  2.07/27~
カテゴリ：データ解析
http://univprof.com/archives/cat_128443.html?p=2

Maximum Information Coefficient(MIC)～変数間の非線形性を考慮した相関係数～
r2・RMSE・MAE・実測値 vs. 推定値プロット以外の、回帰分析結果・回帰モデルによる推定結果の評価方法
外れ値・異常サンプルの検出方法と、その診断の方法～検出に比べて診断は難しい～
モデルの逆解析の難しさ～１週間の献立自動提案システムを例にして～
スケーリングを行わない３つのケース
主成分分析(Principal Component Analysis, PCA)で計算できる主成分の数が少ない？
サンプリングを理解するためのたった１つのコツ～すべての基本は正規乱数をたくさん発生させること～
回帰モデル・クラス分類モデルの精度とモデルの適用領域の広さはトレードオフの関係、アンサンブル学習を活用してその関係を乗り越えろ！

実用的かつ実践的な方法
    説明変数間の独立性を考慮した単純ベイズ (Naïve Bayes, NB) 分類器

2周目を再走して、test0_tips_jp.txtに情報を書き込む



[1b2] 再チェック
精度評価指標と回帰モデルの評価
https://funatsu-lab.github.io/open-course-ware/basic-theory/accuracy-index/
精度評価指標を用いてモデルの良し悪しを評価する上では、以下のようなことに注意を払う必要があります。
* R2, RMSE, MAE はいつでも比較できるわけではない！
  全く同じデータに対して計算した場合のみ相対的な大小が比較可能で、
  異なるデータセット間での指標の比較は意味がありません。
* モデル構築用データ、モデル検証用データ両方に対する精度を考慮する必要がある
  そもそもモデル構築がうまくできていない場合、両データに対する精度がアンバランスになりがちです。
* 予測可能性には限界があることが多い
  データに観測誤差(あるいは実験誤差)がある場合、精度指標の値には何らかの限界値が想定されます。
  例えば生理活性データ(Ki、IC50 等)は同じ系に対しても観測値がばらつくため、
  優秀すぎる精度指標の値は逆に信頼を得られません。
* モデルには適用範囲がある
  機械学習を用いて作成したモデルは、良くも悪くも使用したデータに左右されてしまいます。
  モデル検証用データに対する精度が高くても、外部データ(使用したデータから離れたデータ)を
  同じような精度で予測できるとは限りません。

->
RMSE / MAE < sqrt(pi/2) :各サンプルが同じようなエラー？
RMSE / MAE = sqrt(pi/2) :誤差が正規分布ならいいモデル
RMSE / MAE > sqrt(pi/2) :一部サンプルが大きいエラー？
