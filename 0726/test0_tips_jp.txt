
# -*- coding: utf-8 -*-
"""
Created on Sat Jul 21 17:32:43 2018

@author: Akitaka
"""

機械学習の基本的な流れ
ref:
実践的なデータ解析の手順
http://univprof.com/archives/16-02-11-2849465.html
データ解析の手順の各段階における手法
http://univprof.com/archives/16-05-01-2850729.html
いまさら聞けない？scikit-learnのキホン
https://dev.classmethod.jp/machine-learning/introduction-scikit-learn/


どの機械学習を使えばいいか？が分かるフローチャート
Choosing the right estimator
http://scikit-learn.org/stable/tutorial/machine_learning_map/




sklearnのクラスと関数一覧
API Reference
http://scikit-learn.org/stable/modules/classes.html



kNNのハイパーパラメータ
https://datachemeng.com/knn/
ハイパーパラメータ kの決め方
回帰や分類:CVで決める 正解率、R^2
適用範囲:試行錯誤(一般的にはk=5,10)
ADを決める時の閾値：3σ法より99.7%




One-Class Support Vector Machineのハイパーパラメータ 
https://datachemeng.com/ocsvm/
ν = 0.03 3σ法より99.7%
γはグラム行列の分散を最大化するものを選ぶ
http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html
デフォルトはν=0.5



ランダムフォレストのハイパーパラメータ
https://datachemeng.com/randomforest/
説明変数の選択の割合：CVで決定
サブデータセットの数：基本的には1000
決定木の深さ：深いほどいい

scikit learnのデフォルト値
http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html
説明変数の選択の割合：max_features=sqrt(n_features))
サブデータセットの数：n_estimators=10
決定木の深さ：max_depth=None (総ての葉がpureになるまで)

https://twitter.com/fmkz___/status/1020503846882140160
SVRはこれでいいんだけど、RFのパラメータチューニングのいいやり方知っている方いませんか？
金子さんに前聞いたらdepthはふらずにでtreeの数と説明変数の数だけふると良いとおっしゃってしたね。
あ、depthは一番深いところまでいっちゃってください！





SVM・SVRのハイパーパラメータの値の候補はどうして2のべき乗・累乗なのか？
http://univprof.com/archives/16-06-25-4229971.html
SVMのC・γの候補は、
C: 2^-10,  2^-9,  …,  2^14,  2^15 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

SVRのC・ε・γの候補は
C: 2^-10,  2^-9,  …,  2^14,  2^15 
ε: 2^-15,  2^-14,  …,  2^9,  2^10 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

https://datachemeng.com/supportvectormachine/
SVMのC・γの候補は、
C: 2^-5,  2^-4,  …,  2^9,  2^10
γ: 2^-10, 2^-9,  …,  2^4,  2^5

https://datachemeng.com/supportvectorregression/
SVRのC・ε・γの候補は
C: 2^-5,  2^-4,  …,  2^9,  2^10 
ε: 2^-10, 2^-9,  …,  2^-1, 2^0 
γ: 2^-20, 2^-19, …,  2^9,  2^10




あなたはサポートベクターマシン・回帰 (Support Vector Machine or Regression, SVM or SVR) 
におけるハイパーパラメータの設定に時間がかかっていませんか？
http://univprof.com/archives/16-07-14-4701508.html
SVRのC・ε・γの候補は
C: 2^-10,  2^-9,  …,   2^9,  2^10
ε: 2^-15,  2^-14,  …,  2^9,  2^10 
γ: 2^-20,  2^-19,  …,  2^9,  2^10

[Pythonコードあり] サポートベクター回帰(Support Vector Regression, SVR)の
ハイパーパラメータを高速に最適化する方法
https://datachemeng.com/fastoptsvrhyperparams/
C の候補: 2^-5, 2^-4, …, 2^9, 2^10 (16通り)
ε (イプシロン) の候補: 2^-10, 2^-9, …, 2^-1, 2^0 (11通り)
γ (ガンマ) の候補: 2^-20, 2^-19, …, 2^9, 2^10 (31通り)

高速最適化の手順は2通り
金子研究室：
    1.グラム行列の分散を最大にするγを計算
    2.γopt＋C=3で、εのみ最適化
    3.γopt+εoptで、Cを最適化
    4.εopt+Coptで、γを最適化
大学教授のブログ：
    1.グラム行列の分散を最大にするγを計算
    2.γoptで、Cとεを同時に最適化
ref:
https://datachemeng.com/fastoptsvrhyperparams
http://univprof.com/archives/16-07-14-4701508.html



クロスバリデーション/CVでの分割数
n_splits = 2, 5
https://datachemeng.com/doublecrossvalidation/
http://univprof.com/archives/16-06-12-3889388.html
n_splits = 2, 5, 10
https://datachemeng.com/modelvalidation/


分割方法について
20180426
https://mail.google.com/mail/u/0/#sent/RdDgqcJHpWcvcDjPgjkjXHLgLnDfdlQzrnZXHZlrxmfB
[1c] 分割方法について調べる
KFoldだと、単純に順番通りに分割する
　データの偏りがあった時、各fold間で性能が大きく異なる
StratifiedKFold（デフォルト）では、データないの偏りをなるべく維持しようとする
　少数データの数が少ないと分割ができない場合もある
ShuffleSplitは単純にランダムサンプリングを行う
LeaveOneOutは1つだけを取り出す
　データ数が少ないときに有効

http://scikit-learn.org/0.18/modules/cross_validation.html
> As a general rule, most authors, and empirical evidence,
> suggest that 5- or 10- fold cross validation should be preferred to LOO.
LeaveOneOutは一般的にはあまり使わない？
> ShuffleSplit is thus a good alternative to KFold cross validation
> that allows a finer control on the number of iterations
> and the proportion of samples on each side of the train / test split.
ShuffleSplitが良いらしい

<ref>
scikit learn の Kfold, StratifiedKFold, ShuffleSplit の違い
http://nakano-tomofumi.hatenablog.com/entry/2018/01/15/172427
Machine Learning with Scikit Learn (Part II)
http://aidiary.hatenablog.com/entry/20150826/1440596779
3.1. Cross-validation: evaluating estimator performance
http://scikit-learn.org/0.18/modules/cross_validation.html
【翻訳】scikit-learn 0.18 User Guide 3.1. クロスバリデーション：推定器の成果を評価する
https://qiita.com/nazoking@github/items/13b167283590f512d99a
活動記録　2018/04/11
</ref>




20180718
https://mail.google.com/mail/u/0/#sent/QgrcJHsbjCZNCXqKkMlpLbTXWjKWfzHljSl
Kfold(shuffle=True)とShuffleSplit の違い
1.train, testのサイズ:
    KFoldは常に1:k-1(k=分割数), ShuffleSplitは(分割数とは無関係に)任意の変更が可能
    つまり、trainにもtestにも使わないデータもあり得る。データが多すぎる時に有効
    n_splits:繰り返しの数(デフォ10), test_size:testデータのサイズ(デフォ0.1)
2.CVの各イテレーションで使うデータセット:
    KFold：どれも必ず一度だけtestとして使う。最初にランダムに分割しても
    ShuffleSplit:毎回ランダムに抽出するので、何度もtestに使うもの、一度も使わないものがありえる
example:
test3_shuffle.py

ref:
http://nakano-tomofumi.hatenablog.com/entry/2018/01/15/172427
https://stackoverflow.com/questions/34731421/whats-the-difference-between-kfold-and-shufflesplit-cv
http://aidiary.hatenablog.com/entry/20150826/1440596779
https://qiita.com/nazoking@github/items/13b167283590f512d99a
http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html
http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html






異なるデータセットでの評価方法
http://univprof.com/archives/16-07-04-4453136.html
OK: MAE, NG: R^2








二値類　二次元でのグラフ化
ref: https://pythondatascience.plavox.info/matplotlib/散布図
http://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html




