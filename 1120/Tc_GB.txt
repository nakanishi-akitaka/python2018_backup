# -*- coding: utf-8 -*-
"""
Created on Tue Nov 20 16:36:11 2018

@author: Akitaka
"""

runfile('C:/Users/Akitaka/Downloads/python/1120/Tc_9model.py', wdir='C:/Users/Akitaka/Downloads/python/1120')
Reloaded modules: my_library
0.00 seconds 
Gradient Boosting
GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,
             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,
             max_leaf_nodes=None, min_impurity_decrease=0.0,
             min_impurity_split=None, min_samples_leaf=1,
             min_samples_split=2, min_weight_fraction_leaf=0.0,
             n_estimators=100, presort='auto', random_state=None,
             subsample=1.0, verbose=0, warm_start=False)
{'n_estimators': [10, 50, 100, 200, 500]}
Tc_GB.csv

read train & pred data from csv file


Best parameters set found on development set:
{'n_estimators': 200}
C:  RMSE, MAE, R^2 =  8.782,  6.019,  0.978
CV: RMSE, MAE, R^2 = 24.664, 15.939,  0.829
TST:RMSE, MAE, R^2 = 20.469, 10.970,  0.820

Predicted Tc is written in file Tc_GB.csv

Double Cross Validation
In 10 iterations, average +/- standard deviation
DCV:RMSE, MAE, R^2 = 22.323, 13.698,  0.848 (ave)
DCV:RMSE, MAE, R^2 =  2.466,  0.932,  0.033 (std)

y-randomization
In 10 iterations, average +/- standard deviation
rnd:RMSE, MAE, R^2 = 54.197, 40.005,  0.115 (ave)
rnd:RMSE, MAE, R^2 =  0.644,  0.416,  0.021 (std)
254.81 seconds 