# -*- coding: utf-8 -*-
"""
Created on Tue Nov 20 16:33:15 2018

@author: Akitaka
"""


[1] 機械学習
[1a] サイトで勉強１　金子研究室
22周目: 11/19~11/25
データ解析に関するいろいろな手法・考え方のまとめ
https://datachemeng.com/summarydataanalysis/
一週間の予定
月：数学(行列計算・線形代数・統計・確率)が不安な方へ, データの前処理
火：データセットの可視化・見える化, クラスタリング, 変数選択
水：回帰分析
木：クラス分類, アンサンブル学習, 半教師あり学習 (半教師付き学習)
金：モデルの検証, モデルの適用範囲, モデルの解釈, モデルの逆解析
土：実験計画法, 時系列データ解析 (ソフトセンサーなど)
日：異常検出・異常診断, その他


[todo]
http://neuro-educator.com/mlcontentstalbe/




[1b] 水素化物Tc計算 & my_library.py
[todo]->[done] 
昨日気づいたことを反映したアップデート※昨日のとは番号を変えている

気づいたこと1
    そもそも、予測用のXに、X_testというネーミングがおかしい
->
ネーミングをX_predに変更



気づいたこと2
    > トレーニングデータで構築したモデルと、最終的に用いるモデルとは異なります。
    私のプログラムでは、ハイパーパラメータを最適化した時点でのモデルをそのまま使って予測しているが大丈夫？

GridSearchCV.fit(X_train,y_train) について
1.ハイパーパラメータを最適化する段階ではX_train, ...を分割する
2.最適化後、.predict()を使う時には、
  最適化したパラメータ&X_train,...全部を使って学習し直したモデルを使用していることが判明
3.もう一度.fit(X,y)をやると、X,yを全部使って、最適化もするし、学習もし直す
4.best_estimator_.fit(X,y)をやると、最適化はなしで、学習のみやり直す



気づいたこと3
    C:  RMSE, MAE, R^2 = トレーニングデータに対するスコア
    CV: RMSE, MAE, R^2 = バリデーションデータに対するスコア？
        ※バリデーションデータを用意せず、クロスバリデーションを使う場合。
    P:  RMSE, MAE, R^2 = テストデータに対するスコア "であるべき"なのに、予測用のXを使ってる
->
学習と予測についてテスト
X (y) -> X_train, X_test (y_train, y_test)
に分割して、.fit(X_train, y_train)で学習し、X_test, y_testに対してテスト
2.の反省より、最適化はなし&(X,y)で学習し直して、予測をおこなう
# Re-learning with all data & best parameters -> Prediction
y_pred = gscv.best_estimator_.fit(X, y).predict(X_pred)

あるいは、DCVが「テストデータに対するスコア」の平均になるハズ




[1c] todo処理
[todo] -> [doing]
    水素化物Tc予測プログラム 更新の余地
    * 説明変数の増加 + PCAなど
-> 実行中

    * Tc=0Kとの分類＋回帰では？
-> 予定
そもそもTc = 0Kのデータを集める
安定に存在できない組成比があるのをTc=0Kとしてデータベースにいれる？

[todo] -> ????
考察
kNNやOLSでもいいから、実現できないか？
個性的な人工知能をつくる
https://datachemeng.com/uniqueartificialintelligence/
1.アウトプットの信頼性も一緒に返してくれる
    ADorデータ密度がその一種。GPRやアンサンブル学習なら、予測値と同時に分散を出力できる。
2.どんなデータがあれば、信頼性が上がるか教えてくれる
    ADでないが、ADに近い領域を表示できればいいのでは？
3.逆解析で複数のアウトプットを返すときに、補足情報によって順位づけしてくれる
    逆解析する場合、異なるxに対して同じyが出力されることがある
    その際、1.によりyの信頼度も出力すれば、それでランク付けできる
4.どうしてそのアウトプットになったか教えてくれる
    補完みたいな手法、ノンパラメトリック回帰の場合は、近くのデータがそうだから、としか言えない(kNNなど)
        強いて言えば、近く(と機械が判断した)データを表示するぐらいか
    モデルを設定する、パラメトリック回帰の場合は、理解しやすい
    ただし、ニューラルネットワークのような複雑すぎるものは厳しい

1.4.ができるかは手法次第な部分がある
1.ができれば、3.はほぼ自動的にできる
AD, データ密度が計算できれば、2.はすぐできる
一応、kNNでそれなりのことはできるっぽい



[1d] 考察
機械学習って、結局はただの補完じゃないの？
線形であれ非線形であれ
線形補完の範囲をデータのある領域全部でやる　→　最小二乗法ともいえる

20180919のPLS, LWPLS考察より
PLSは単純な線形モデル
LWPLSは、予測したいデータの近くの学習データをなるべく再現するよう線形モデルを組む
小さい区間での線形補完を繰り返しやってるようなものでは？

少なくとも、最初からモデルの形を仮定しないノンパラメトリック回帰はほぼ補完と同じ印象
モデルの形を仮定するの、パラメトリック回帰は、全区間での補完とも言える？
SVR：カーネル関数の形で補間　ガウス関数など
ランダムフォレスト：ある範囲にあるデータを線形y=constantで近似したようなもの

結局は補完なのであれば、特別目新しい発見はないのか？
画像識別のような、説明変数が多いもので、
かつ、単純な補完が難しいものであれば、機械学習である意味がありそう



11/20
第5回 競馬予測の入力となる特徴量を作る
https://alphaimpact.jp/2017/02/09/make-feature/
今回はカテゴリデータを主とした特徴量の作成方法について解説しましたが、その重要性を感じていただけたでしょうか。
すでに第5回目だというのにまだ予測ロジックについての話が出てこないではないかと思われてる方も多いかと思いますが、
入力となるデータ作りはただの手の運動ではなく入念な設計が必要となるクリエイティブなプロセスで、
実際のAlphaImpactの開発では予測ロジックの作成以上に時間を要しています。 
最強の競馬人工知能を作る一番の近道は最強の競馬特徴量職人になることだと言っても過言ではないでしょう。

説明変数の作成方法が大事？

野球、マネー・ボール　
新しい評価基準 = 説明変数 OPSを作成
自分で考えた結果

将棋
評価関数　あるいはその入力＝説明変数＝2,3,4駒関係
考えた結果？

ディープラーニングによる画像識別
説明変数は勝手に作成する　そのため、人間に解釈できる形とは限らない
人間は一切考えていない

物性物理学の場合は？
質量やら第一イオン化エネルギーやら電気陰性度などで作成される
将棋・野球同様に、自分で考えたもの

競馬や将棋、画像認識でもそうだが、これを特徴量にすれば絶対大丈夫というものはない
ただ、将棋や画像認識については、「最小限必要なライン」はハッキリしている
    駒の位置と持ち駒、画像データそのまま
物性物理学でいえば、原子の種類と個数？
第一原理計算は、原子の種類と位置だが...
どちらにせよ、圧力や磁場はなしとしている

みにくいアヒルの子の定理？
http://ibisforest.org/index.php?醜いアヒルの子の定理
    これは，各特徴量を全て同等に扱っていることにより成立する定理． 
    すなわち，クラスというものを特徴量で記述するときには，何らかの形で特徴量に重要性を考えていることになる． 
    この定理は，特徴選択や特徴抽出が識別やパターン認識にとって本質的であることを示唆している．

https://www.cresco.co.jp/blog/entry/2488/
…ちょっと詭弁っぽいですね。
実は、ノーフリーランチ定理が「考えうる全てのコスト関数に対して」というのがミソだったのと同じように、
これも「あらゆる種類の共通点 (や差異) を同じ重みで考える」というところがミソになっています。
実際には、人間が何かの類似性や差異を判断するときには、重要視するものとあまりしないものと、
意識的・無意識的に重み付けしているのです。
逆に、そうした適度な重み付けがないと、何かを類似度に基づいてグループ分けすることはできなくなってしまう、
というのが、この定理なのです。

機械学習を使って画像を分類する場合も、
要は「どの類似性・差異を重要視するか」ということを教師データを使って学習させています。
理屈から言うと、データセットに対してどんな分類の仕方でもできてしまいます 
(ノーフリーランチ定理からすると、学習しやすい分類の仕方となかなか学習が進まない分類の仕方はあるでしょう)が、
そこに何らかの価値観を入れ込むのです。

※ノーフリーランチ定理
「考えうる全てのコスト関数」というのがミソなのですが、それでも、それらを相手にしては、
凄いアルゴリズムとそうでもないアルゴリズムは変わらない、と言われてしまうと困ってしまいます。
最適値を探索するアルゴリズムを工夫することは無意味なのでしょうか? もちろん、そんなことはありません。

一般的に、ある領域の問題に対するコスト関数には、「ありとあらゆる」ものは出てきません。
何らかの特徴というか癖というか、そんなようなものがあります。
ノーフリーランチ定理が主張するのは、「ある領域の問題」に対する最適化アルゴリズムは、
その特徴や癖を事前知識としたりして、その領域に特化したものにせねばならない 
(それをぜんぜん違う領域に適用すると性能がでないかもしれない)、ということなのです。

機械学習にもやり方がいろいろありますが、「どれか一つのやり方で万事 ok」とはいかない、ということでもあります。
問題の領域に合わせて、やり方を選んだり工夫したりする必要があるのです。


http://www.kamishima.net/archive/mldm-overview.pdf
類似した対象が集まったクラスというものを実世界で見いだしているならば，
対象のある特徴を重視したり，逆に軽視したりしているということである．
そして，どの特徴を重視したり軽視したりするかは形式的な判断の範疇の外で決めている

予測問題にとって重要な特徴は限られているという仮説を支持
→ 次元削減，特徴選択，正則化の技法などが有効である理由


http://d.hatena.ne.jp/akkikiki/20130612/1371049768
自分が特に気に入っているのは「みにくいアヒルの子定理」の直観的解説の部分。
これは「人は自分の価値基準（＝事前知識orコスト関数と自分は解釈）を用いないと、
最適かどうかを判断できなくなる」と自分は解釈している。
あなたが人生で何を大切にするのか？を考えないと、現実でも機械学習の世界でも何も判断できないよ、
というメッセージが自分の心に刻み込まれた。

https://www.slideshare.net/mmktakahashi/ss-13694313
p.15あたりから、みにくいアヒルの子の定理
特徴選択・特徴抽出が識別・認識の本質 p.22


http://www.ism.ac.jp/shikoin/training/dstn/pdf/C4.pdf
3. 機械学習の一般的な問題
• No-free-lunch定理 [Wolpert and Macready、1995]
「どの学習機械に対しても、ランダム推測の方が優れている
目的関数が少なくとも一つ存在する 」
• みにくいアヒルの子定理 [渡辺慧, 1969]
「課題から独立した特徴量/モデルは存在しない」

https://www.slideshare.net/dsuket/ss-57488780
p.29
アルゴリズム選択時の注意 
データ特性などに適したアルゴリズムを選択すること データの分布を前提に置いているものもある。 [10] 
ノーフリーランチ定理
コスト関数の極値を探索するあらゆるアルゴリズムは、
全ての可能なコスト関数に適用した結果を平均すると同じ性能となる 
あらゆる問題で性能の良い万能な学習アルゴリズムは存在しない — Wolpert and Macready、1995年



